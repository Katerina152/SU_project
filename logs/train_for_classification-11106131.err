The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) devel   2) math
/home/users/ksa828/cool_project/venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[rank: 0] Seed set to 42
2025-12-03 14:06:44,801 | INFO | Logging to ISIC2019/isic_vit_binary_224/seed_42/train.log
2025-12-03 14:06:44,801 | INFO | Experiment root = ISIC2019/isic_vit_binary_224
2025-12-03 14:06:44,801 | INFO | Seed directory  = ISIC2019/isic_vit_binary_224/seed_42
2025-12-03 14:06:44,801 | INFO | [dermatology] Train transform:
Compose(
    Resize(size=(224, 224), interpolation=bicubic, max_size=None, antialias=True)
    ToTensor()
    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
)
2025-12-03 14:06:44,801 | INFO | [dermatology] Eval  transform:
Compose(
    Resize(size=(224, 224), interpolation=bicubic, max_size=None, antialias=True)
    ToTensor()
    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
)
2025-12-03 14:06:44,801 | INFO | [dermatology] Test  transform:
Compose(
    Resize(size=(224, 224), interpolation=bicubic, max_size=None, antialias=True)
    ToTensor()
    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
)
/home/users/ksa828/cool_project/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
2025-12-03 14:06:45,817 | INFO | Dataloaders created with keys: ['train', 'val', 'test']
2025-12-03 14:06:45,817 | INFO | #train batches per epoch: 1
2025-12-03 14:06:45,817 | INFO | #val batches per epoch:   1
2025-12-03 14:06:45,817 | INFO | #test batches per epoch:  1
2025-12-03 14:06:46,483 | INFO | First train batch pixel_values.shape = torch.Size([18, 3, 224, 224])
2025-12-03 14:06:46,484 | INFO | First train batch labels.shape       = torch.Size([18])
2025-12-03 14:06:46,484 | INFO | pixel_values dtype = torch.float32, device = cpu
2025-12-03 14:06:46,484 | INFO | labels dtype       = torch.int64, device = cpu
2025-12-03 14:06:46,486 | INFO | pixel_values: min=-1.0000, max=1.0000, mean=0.1466
2025-12-03 14:06:46,486 | INFO | num_classes (data) = 9
2025-12-03 14:06:46,486 | INFO | num_classes (cfg)  = 9
2025-12-03 14:06:46,486 | INFO | First 5 rows of train CSV:
2025-12-03 14:06:46,603 | INFO | 
          image  MEL   NV  BCC   AK  BKL   DF  VASC  SCC  UNK
0  ISIC_0000360  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0
1  ISIC_0031596  0.0  1.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0
2  ISIC_0069981  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0
3  ISIC_0058265  0.0  0.0  0.0  0.0  1.0  0.0   0.0  0.0  0.0
4  ISIC_0061683  0.0  0.0  1.0  0.0  0.0  0.0   0.0  0.0  0.0
2025-12-03 14:06:46,605 | INFO | Label columns: ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']
2025-12-03 14:06:46,606 | INFO | Class counts (sum over labels): {'MEL': 4.0, 'NV': 9.0, 'BCC': 2.0, 'AK': 0.0, 'BKL': 3.0, 'DF': 1.0, 'VASC': 0.0, 'SCC': 1.0, 'UNK': 0.0}
2025-12-03 14:06:46,606 | INFO | Total label sum across all classes: 20.0 (num_samples = 20)
Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-12-03 14:06:51,784 | INFO | Model built from config:
2025-12-03 14:06:51,785 | INFO | VisionTransformerWithHead
2025-12-03 14:06:51,785 | INFO | Lightning task         = single_label_classification
2025-12-03 14:06:51,785 | INFO | Lightning output_dir   = ISIC2019/isic_vit_binary_224/seed_42
2025-12-03 14:06:51,785 | INFO | Lightning experiment_name set to empty string for flat structure.
2025-12-03 14:06:51,838 | INFO | TensorBoard / CSV logs will be in: ISIC2019/isic_vit_binary_224/seed_42
2025-12-03 14:06:51,841 | INFO | Checkpoints will be saved under: ISIC2019/isic_vit_binary_224/seed_42/checkpoints
2025-12-03 14:06:51,841 | INFO | ===== Trainer hardware configuration =====
2025-12-03 14:06:51,841 | INFO | SLURM num_nodes          = 1
2025-12-03 14:06:51,841 | INFO | CUDA visible GPUs        = 1
2025-12-03 14:06:51,841 | INFO | use_gpu                  = True
2025-12-03 14:06:51,841 | INFO | Chosen Lightning strategy= auto
2025-12-03 14:06:51,841 | INFO | =========================================
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
2025-12-03 14:06:51,892 | INFO | Starting training...
/home/users/ksa828/cool_project/venv/lib/python3.12/site-packages/lightning/fabric/loggers/csv_logs.py:268: Experiment logs directory ISIC2019/isic_vit_binary_224/seed_42/ exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!
/home/users/ksa828/cool_project/venv/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:881: Checkpoint directory /home/users/ksa828/cool_project/ISIC2019/isic_vit_binary_224/seed_42/checkpoints exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type                      | Params | Mode  | FLOPs
--------------------------------------------------------------------
0 | model | VisionTransformerWithHead | 86.4 M | train | 0    
--------------------------------------------------------------------
6.9 K     Trainable params
86.4 M    Non-trainable params
86.4 M    Total params
345.585   Total estimated model params size (MB)
4         Modules in train mode
215       Modules in eval mode
0         Total Flops
SLURM auto-requeueing enabled. Setting signal handlers.
/home/users/ksa828/cool_project/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
/home/users/ksa828/cool_project/venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:317: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
/home/users/ksa828/cool_project/venv/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:534: Found 215 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
/home/users/ksa828/cool_project/venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
`Trainer.fit` stopped: `max_epochs=2` reached.
2025-12-03 14:07:10,431 | INFO | Starting test...
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
SLURM auto-requeueing enabled. Setting signal handlers.
2025-12-03 14:07:12,861 | INFO | Training script finished.
